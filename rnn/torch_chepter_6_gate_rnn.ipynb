{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V-CV84lfOZ3"
      },
      "source": [
        "# GateRNN\n",
        "本篇主要是想利用pytorch复现《深度学习进阶--自然语言处理》第六章内容，读取数据分析结果依旧用书中代码。\n",
        "RNN部分主要参考 \n",
        "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "\n",
        "GRU文档：https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TW078ElfOZ7"
      },
      "source": [
        "## 模型创建"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9tSyPPP2fOZ7",
        "outputId": "17f4baf6-6791-49b9-d9db-5294fe236581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use device Tesla K80 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5903e14ab112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     ]\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;34m:\u001b[0m    \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Invalid device string: 'Tesla K80'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# torch.cuda.is_available\n",
        "device = torch.cuda.get_device_name() if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "\n",
        "print(f\"use device {device} \")\n",
        "\n",
        "class Rnnlm(nn.Module):\n",
        "    def __init__(self,vocab_size=10000,wordvec_size=1000):\n",
        "        super(Rnnlm,self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,wordvec_size)\n",
        "        self.rnn = nn.LSTM(wordvec_size, 256 ,batch_first = True,bias=False)\n",
        "        self.affine = nn.Linear(256,vocab_size,bias=False)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.flatten = nn.Flatten(0,-2)\n",
        "\n",
        "    def forward(self,input,h_c):\n",
        "        embeded = self.embedding(input)\n",
        "        output = embeded\n",
        "\n",
        "\n",
        "        output, hc = self.rnn(output,h_c)\n",
        "        output = self.affine(output)\n",
        "        output = self.softmax(output)\n",
        "        output = self.flatten(output)\n",
        "        return output,hc\n",
        "\n",
        "\n",
        "    ## 测试模型\n",
        "x  = [\n",
        "        [1,2,3,4],\n",
        "        [5,6,7,8],\n",
        "        [9,10,11,12]\n",
        "    ]\n",
        "\n",
        "x = torch.Tensor(x).long().to(device = device)\n",
        "\n",
        "input = x[:,   :    -1].to(device=device)\n",
        "target =x[:,1  : ].to(device=device)\n",
        "\n",
        "print(input)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#hiden = torch.zeros((1,3,5),dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "# tmodel = Rnnlm(50,5).to(device = device)\n",
        "\n",
        "\n",
        "# target = torch.flatten(target)\n",
        "# criterion = torch.nn.NLLLoss()\n",
        "# optimizer = torch.optim.SGD(tmodel.parameters(),lr = 0.9)\n",
        "# for i in range(1000):\n",
        "#     hidden = None\n",
        "#     out ,hidden= tmodel(input,hidden)\n",
        "#     loss = criterion(out,target)\n",
        "\n",
        "#     print(loss.item())\n",
        "#     optimizer.zero_grad()\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "\n",
        "# embed = nn.Embedding(20,5)\n",
        "# input = embed(x)\n",
        "# print(f\"input.shape:{input.shape}\")\n",
        "\n",
        "# lstm = nn.LSTM(5,20)\n",
        "# c = None\n",
        "\n",
        "# output,c = lstm(input,None)\n",
        "\n",
        "# print(output.shape)\n",
        "# print(c)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(f\"out.shape:{out.size()}\")\n",
        "\n",
        "# softmax = nn.Softmax(dim=-1)\n",
        "# test = torch.zeros((2,5,4),dtype=torch.float32)\n",
        "# test[:,:,3] = 1\n",
        "\n",
        "# test[0,2,0] = 3\n",
        "# print(test)\n",
        "# print(softmax(test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TOVPaqfFfOZ-",
        "outputId": "c6bdfbf0-a66f-41dc-c960-36b56b398a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.return_types.topk(\n",
            "values=tensor([[0.6218, 0.3233, 0.0197, 0.0176, 0.0063]], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([[ 3, 10, 11,  7,  2]], device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[2]]).to(device=device)\n",
        "h_c = None\n",
        "\n",
        "out, hc = tmodel.forward(a,None)\n",
        "print(out.topk(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40n6eWlSfOZ-"
      },
      "outputs": [],
      "source": [
        "\n",
        "## 训练弄型\n",
        "def train(model:Rnnlm,criterion,optimizer,input,target,h = None):\n",
        "    optimizer.zero_grad()\n",
        "    pred ,h = model(input,h)\n",
        "    loss = criterion(pred)\n",
        "    loss.backfard()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss,h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9IByf6TfOZ_"
      },
      "outputs": [],
      "source": [
        "# def train_dataset(model:Rnnlm,\n",
        "#  criterion = nn.CrossEntropyLoss(),\n",
        "#  optimizer:torch.optim.Optimizer = None,\n",
        "#  input = None ,\n",
        "#  target = None\n",
        "#   max_iters = 100,\n",
        "#   batch_size = 500,\n",
        "#   time_size = 10 ):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdD5o7X5fOZ_"
      },
      "source": [
        "## 加载数据\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4kDi-0cfOaB"
      },
      "source": [
        "### colab加载主公共模块"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dVRS3QJzfOaB",
        "outputId": "d00fecb8-4ac0-4756-d718-ec658c10559c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/ml/nlp/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gciMLI9fOaC"
      },
      "source": [
        "### 本机环境中用当前前目录"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHfxiXQgfOaC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3gMgnXmRfOaC",
        "outputId": "c8983672-1539-44e9-ca7a-cb1f89cc0f5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus size 1000 ,vocabulary size : 10000, \n",
            "vocab_size = 10000 wordvec_size= 100 hidden_size = 100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rnnlm(\n",
              "  (embedding): Embedding(10000, 100)\n",
              "  (rnn): LSTM(100, 256, bias=False, batch_first=True)\n",
              "  (affine): Linear(in_features=256, out_features=10000, bias=False)\n",
              "  (softmax): Softmax(dim=-1)\n",
              "  (flatten): Flatten(start_dim=0, end_dim=-2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from common.optimizer import SGD\n",
        "from dataset import ptb\n",
        "import time \n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "time_size = 10\n",
        "\n",
        "wordvec_size = 100\n",
        "hidden_size=100\n",
        "\n",
        "lr = 0.1\n",
        "max_epoch = 100\n",
        "\n",
        "\n",
        "corpus , word_to_id,id_to_word = ptb.load_data('train')\n",
        "corpus_size = 1000\n",
        "\n",
        "\n",
        "#corpus = corpus[:corpus_size]\n",
        "vocab_size = len(word_to_id)\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "\n",
        "\n",
        "data_size = len(corpus)\n",
        "print(\"corpus size %d ,vocabulary size : %d, \" % (corpus_size,vocab_size))\n",
        "\n",
        "max_iters = data_size // (batch_size * time_size)\n",
        "time_idx = 0\n",
        "total_loss = 0\n",
        "\n",
        "\n",
        "loss_count = 0\n",
        "ppl_list = []\n",
        "\n",
        "\n",
        "print(f\"vocab_size = {vocab_size} wordvec_size= {wordvec_size} hidden_size = {hidden_size}\")\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Rnnlm(vocab_size,wordvec_size)\n",
        "model.to(device=device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "model.train()\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXjaD99LfOaD"
      },
      "source": [
        "## 训练数据读取\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iKGtoAXgfOaD",
        "outputId": "b7f5add4-44ac-49ce-a9f4-a8dc30f7c6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-40a2c3cd7ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_iterval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mloss_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch  {epoch }/{max_epoch}\\t|\\t time :{time.time() - start_time}[s] \\t|\\t perplexity:{ppl}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mloss_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'start_time' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "time_size = 20\n",
        "batch_size = 200\n",
        "\n",
        "max_grad = 0.25\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.8)\n",
        "\n",
        "eval_iterval = 20\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    \n",
        "   \n",
        "    for  iter in range(max_iters -1):\n",
        "\n",
        "\n",
        "        start_idx = iter * (batch_size * time_size)\n",
        "        end_idx = (iter + 1) * (batch_size * time_size)\n",
        "\n",
        "        batch_x = xs[start_idx:end_idx]\n",
        "        batch_t = ts[start_idx:end_idx]\n",
        "\n",
        "\n",
        "        # batch_x = xs[0 : 500 * time_size]\n",
        "        # batch_t = ts[0 : 500 * time_size]\n",
        "\n",
        " \n",
        "        batch_x = batch_x.reshape(batch_size,time_size) \n",
        "        #batch_t = batch_t.reshape(batch_size,time_size)\n",
        "\n",
        "\n",
        "        batch_x = torch.from_numpy(batch_x).to(device=device)\n",
        "        batch_t = torch.from_numpy(batch_t).to(device=device)\n",
        "\n",
        "\n",
        "        h = None\n",
        "        model.zero_grad()\n",
        "        pred  ,h = model(batch_x,h)\n",
        "        loss = criterion(pred,batch_t)\n",
        "        loss.backward()\n",
        "        \n",
        "      #   params = model.parameters()\n",
        "\n",
        "      #   for param in params:\n",
        "      # ##    print(param.grad.data)\n",
        "      #     param.data.add_(param.grad.data, alpha= -1)\n",
        "      \n",
        "       # loss , h = train(model,criterion,optimizer,batch_x,batch_t,h,max_grad)\n",
        "\n",
        "      #  print(loss)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loss_count += 1\n",
        "        if (iter % eval_iterval) == 0:\n",
        "            ppl = math.exp(total_loss / loss_count)\n",
        "            print(f\"epoch  {epoch }/{max_epoch}\\t|\\t time :{time.time() - start_time}[s] \\t|\\t perplexity:{ppl}\")\n",
        "            total_loss = 0\n",
        "            loss_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-4O3ItLsfOaE",
        "outputId": "18eb75f6-1290-4000-935c-16169bd2dfd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f0f75abd3be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRnnlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwordvec_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    904\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "model = Rnnlm(100,wordvec_size)\n",
        "model.to(device=device)\n",
        "\n",
        "batch_size = 200\n",
        "time_size = 10\n",
        "max_grad = 0.25\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "\n",
        "adam = torch.optim.Adam(model.parameters(),lr=1)\n",
        "\n",
        "eval_iterval = 20\n",
        "\n",
        "ppl_list = []\n",
        "\n",
        "loss_list = []\n",
        "loss = 0\n",
        "h = None\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    \n",
        "   \n",
        "    for  iter in range(max_iters -1):\n",
        "\n",
        "\n",
        "        # start_idx = iter * (batch_size * time_size)\n",
        "        # end_idx = (iter + 1) * (batch_size * time_size)\n",
        "\n",
        "        start_idx = 0 * (batch_size * time_size)\n",
        "        end_idx = (0 + 1) * (batch_size * time_size)\n",
        "\n",
        "        batch_x = xs[start_idx:end_idx]\n",
        "        batch_t = ts[start_idx:end_idx]\n",
        "\n",
        "\n",
        "        # batch_x = xs[0 : 500 * time_size]\n",
        "        # batch_t = ts[0 : 500 * time_size]\n",
        "\n",
        " \n",
        "        batch_x = batch_x.reshape(batch_size,time_size) \n",
        "        #batch_t = batch_t.reshape(batch_size,time_size)\n",
        "\n",
        "\n",
        "        batch_x = torch.from_numpy(batch_x).to(device=device)\n",
        "        batch_t = torch.from_numpy(batch_t).to(device=device)\n",
        "\n",
        "        adam.zero_grad()\n",
        "        pred  ,h = model(batch_x,h)\n",
        "        l  = criterion(pred,batch_t)\n",
        "        l.backward()\n",
        "        adam.step()\n",
        "\n",
        "        total_loss += l\n",
        "\n",
        "       # h = None\n",
        "        # optimizer.zero_grad()\n",
        "        # model.zero_grad()\n",
        "        # pred  ,h = model(batch_x,h)\n",
        "        # l  = criterion(pred,batch_t)\n",
        "        # total_loss += l.item()\n",
        "        # loss += l\n",
        "\n",
        "        #params = model.parameters()\n",
        "\n",
        "    #     for param in params:\n",
        "    #   ##    print(param.grad.data)\n",
        "    #       param.data.add_(param.grad.data, alpha= -1)\n",
        "      \n",
        "       # loss , h = train(model,criterion,optimizer,batch_x,batch_t,h,max_grad)\n",
        "\n",
        "      #  print(loss)\n",
        "      \n",
        "        \n",
        "\n",
        "        # total_loss += loss.item()\n",
        "        loss_count += 1\n",
        "        if (iter % eval_iterval) == 0:\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss ,h = 0,None\n",
        "\n",
        "            ppl = np.exp(total_loss / loss_count)\n",
        "            print(f\"epoch  {epoch }/{max_epoch}\\t|\\t time :{time.time() - start_time}[s] \\t|\\t perplexity:{ppl}\")\n",
        "            \n",
        "#            ppl_list.append(ppl)\n",
        "            avg_loss = total_loss / loss_count\n",
        "            loss_list.append(avg_loss)\n",
        "            total_loss , loss_count = 0, 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWx9Ri9MfOaF",
        "outputId": "2909fdd0-c0bf-447f-ed73-d1bcd9356ed3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x = np.arange(len(loss_list))\n",
        "plt.plot(x,loss_list)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuEo9duyfOaF",
        "outputId": "4e29d4ba-bc37-4f11-9fff-a47044d69a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.6537e-03, 5.0106e-03, 6.9797e-03, 4.6286e-03, 1.9606e-03, 7.5650e-04,\n",
            "         7.9434e-01, 2.5173e-02, 3.2794e-03, 1.2473e-03, 3.6444e-03, 2.3564e-03,\n",
            "         5.1677e-03, 1.6386e-03, 3.0004e-03, 1.1903e-03, 1.6400e-03, 4.9065e-03,\n",
            "         9.4263e-04, 1.6097e-03, 1.2935e-03, 1.3746e-03, 1.2469e-03, 1.4807e-03,\n",
            "         6.8199e-04, 1.9540e-03, 1.3096e-03, 4.9108e-03, 7.2063e-04, 1.5059e-03,\n",
            "         2.0091e-03, 2.1672e-03, 2.1353e-03, 9.8396e-04, 3.4713e-03, 1.2766e-03,\n",
            "         1.5655e-03, 1.3207e-03, 2.6648e-03, 1.5454e-03, 1.2041e-03, 8.7829e-04,\n",
            "         1.0790e-03, 2.0018e-03, 2.1206e-03, 6.7047e-04, 1.8060e-03, 1.7785e-03,\n",
            "         1.4840e-03, 1.3894e-03, 1.5312e-03, 1.6352e-03, 1.4807e-03, 1.4497e-03,\n",
            "         1.6310e-03, 1.5739e-03, 1.5879e-03, 1.4768e-03, 1.5889e-03, 1.2662e-03,\n",
            "         1.6382e-03, 1.4607e-03, 1.6132e-03, 1.8467e-03, 1.5962e-03, 1.2794e-03,\n",
            "         1.7894e-03, 1.5789e-03, 1.6658e-03, 1.7412e-03, 1.7732e-03, 1.6717e-03,\n",
            "         1.3683e-03, 1.4819e-03, 1.3830e-03, 1.3557e-03, 1.5209e-03, 1.5131e-03,\n",
            "         1.7111e-03, 1.9341e-03, 1.6199e-03, 1.8298e-03, 1.4657e-03, 1.4100e-03,\n",
            "         1.3700e-03, 1.5641e-03, 1.3131e-03, 1.7027e-03, 1.5436e-03, 1.9582e-03,\n",
            "         1.5681e-03, 1.5725e-03, 1.4654e-03, 1.6740e-03, 1.6792e-03, 1.5498e-03,\n",
            "         1.5295e-03, 1.7217e-03, 1.5589e-03, 1.5981e-03]],\n",
            "       grad_fn=<ReshapeAliasBackward0>)\n",
            "torch.return_types.topk(\n",
            "values=tensor([[0.7943, 0.0252, 0.0070, 0.0052, 0.0050, 0.0049]],\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([[ 6,  7,  2, 12,  1, 27]]))\n"
          ]
        }
      ],
      "source": [
        "corpus[0:20]\n",
        "\n",
        "input = torch.Tensor([[5]]).long()\n",
        "tt,h = model.forward(input,None)\n",
        "print(tt)\n",
        "print(tt.topk(6))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQUK-npbfOaF"
      },
      "source": [
        "## 保存模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV4JXicrfOaG"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/ml/nlp/lstm-ptb.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5v1d50BfOaG"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYE_SRJBfOaG"
      },
      "source": [
        "## 加载模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aju0gz19fOaG"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dIiMZiyfOaG"
      },
      "source": [
        "## 测试"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuWClnU4fOaH"
      },
      "outputs": [],
      "source": [
        "from common.util import most_similar\n",
        "\n",
        "\n",
        "# ## CBOW 模型的评价\n",
        "\n",
        "# print(model.inEmbedding.weight.shape)\n",
        "\n",
        "\n",
        "word_vecs = model.embedding.weight.detach().to(device = \"cpu\").numpy()\n",
        "\n",
        "querys = ['you','year','car','toyota']\n",
        "\n",
        "for query in querys:\n",
        "  most_similar(query,word_to_id,id_to_word,word_vecs)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "fe85713bd73e29e553e0fe93aab7a5c1beebd30dbde9209efd93f425af696249"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('language')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "torch_chepter_6_gate_rnn.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}